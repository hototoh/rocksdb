// This autogenerated skeleton file illustrates how to build a server.
// You should copy it to another filename to avoid overwriting it.
#include <iostream>
#include <thread>

#include <thrift/protocol/TBinaryProtocol.h>
#include <thrift/server/TThreadPoolServer.h>
#include <thrift/transport/TServerSocket.h>
#include <thrift/transport/TBufferTransports.h>
#include <thrift/concurrency/PosixThreadFactory.h>
#include <thrift/concurrency/ThreadManager.h>
#include <thrift/concurrency/Exception.h>

#include "rocksdb/db.h"
#include "rocksdb/env.h"
#include "rocksdb/slice.h"
#include "rocksdb/options.h"
#include "db/filename.h"
#include "util/random.h"

#include "./gen-cpp/replication_types.h"
#include "./gen-cpp/Replication.h"

#include "replication_common.h"
#include "replication_master.h"

namespace rocksdb {
namespace {

inline std::string RandomString(Random* rnd, int len) {
  static const char kTestChars[] = {
    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o'
  };
  std::string result;
  for (int i = 0; i < len; i++) {
    result += kTestChars[rnd->Uniform(sizeof(kTestChars))];
  }
  return result;
}

inline SessionID getNewReplicationID() {
  Random rnd(109);
  return RandomString(&rnd, 16);
}

} // namespace anon

// --- ReplicationHandler methods ------

ReplicationHandler::ReplicationHandler(DB *_db) {
  db = _db;
  env = db->GetEnv();  
}

ReplicationHandler::~ReplicationHandler() { }

bool ReplicationHandler::NewFileDeletionEntry() {
  for (int i = 0 ; i < 3; i++) {
    SessionID session_id = getNewReplicationID();
    auto iter = file_deletion_lock_table.find(session_id);
    if (iter == file_deletion_lock_table.end()) {
      int64_t timestamp;
      Status s = env->GetCurrentTime(&timestamp);
      if(!s.ok()) continue;

      file_deletion_lock_table.insert(std::make_pair(session_id, timestamp));
      return true;
    } 
  }
  return false;
}

// Update the time in file_deletion_lock_table. If entry doesn't exist,
// some file may be deleted and we must throw error to the client.
bool ReplicationHandler::UpdateFileDeletionEntry(const SessionID& session_id) {
  auto iter = file_deletion_lock_table.find(session_id);
  if (iter == file_deletion_lock_table.end()) {
    return false;
  }

  // we don't need to lock the table here
  int64_t timestamp;
  Status s = env->GetCurrentTime(&timestamp);
  if(!s.ok()) return false;

  iter->second = timestamp;
  return true;
}

bool ReplicationHandler::DeleteFileDeletionEntry(const SessionID& session_id) {
  auto iter = file_deletion_lock_table.find(session_id);
  if (iter == file_deletion_lock_table.end()) {
    return false;
  }

  file_deletion_lock_table.erase(iter);
  return true;
}

void ReplicationHandler::DisableFileDeletions(SessionID& _return) {
  Status s;
  s = db->DisableFileDeletions();
  if (!s.ok()) {
    db->EnableFileDeletions(false);
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Cannot disabel file deletion in master");
  }
  
  if(!NewFileDeletionEntry()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Fail to create new replication ID");
  }
  return ;
}

bool ReplicationHandler::EnableFileDeletions(const SessionID& session_id,
                                             const bool force) {
  Status s;
  db->EnableFileDeletions(force);
  if (!s.ok()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Fail to enable file deletion");
  }

  // Even if Fail to delete the entry from file_deletion_lock_table,
  // it does not matter.
  bool res = DeleteFileDeletionEntry(session_id);
  return true;
}

void ReplicationHandler::GetLiveFiles(
    std::vector<ReplicationFileInfo> & _return, 
    const SessionID& session_id,
    const bool flush_before_replication) {
  Status s;
  std::vector<std::string> live_files;
  uint64_t manifest_file_size = 0;

  s = db->GetLiveFiles(live_files, &manifest_file_size, 
                       flush_before_replication);
  if (!s.ok()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Fail to get live files");
  }
  
  for(auto iter = live_files.begin(); iter != live_files.end(); ++iter) {
    ReplicationFileInfo info;
    std::string& filename = *iter;
    uint64_t number;
    FileType type;
    bool ok;
    if(filename.size() > 0 && filename[0] == '/') {
      continue;
    }
    
    ok = ParseFileName(filename, &number, &type);
    if (!ok) {
      throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                             "Can't parse file name. This is very bad");
    }

    // we should only get sst, manifest and current files here
    assert(type == kTableFile || type == kDescriptorFile ||
           type == kCurrentFile);
    info.src_dir = db->GetName();
    info.src_fname =  filename;

    _return.push_back(info);
  }
  return ;
}

void ReplicationHandler::GetLiveWALFiles(
    std::vector<ReplicationFileInfo> & _return,
    const SessionID& session_id) {
  Status s;
  VectorLogPtr live_wal_files;

  // if we didn't flush before backup, we need to also get WAL files
  // if (options_.backup_log_files) {
  if (true) {
    // returns file names prefixed with "/"
    s = db->GetSortedWalFiles(live_wal_files);
  }
  if (!s.ok()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Fail to get live wal files");
  }
  
}

void ReplicationHandler:: GetFileData(ReplicationFileData& _return, 
                                      const SessionID& session_id,
                                      const ReplicationFileInfo& file_info,
                                      const int64_t transfer_data_size) {
  const std::string& src_path = file_info.src_dir + file_info.src_fname;
  const uint64_t position = file_info.position;
  Status s;
  unique_ptr<SequentialFile> src_file;
  EnvOptions env_options;
  env_options.use_mmap_writes = false;
  env_options.use_os_buffer = false;

  if(!UpdateFileDeletionEntry(session_id)) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Cannot disabel file deletion in master");
  }

  s = env->NewSequentialFile(src_path, &src_file, env_options);
  if (!s.ok()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Fail to open SequentialFile");    
  }

  unique_ptr<char[]> buf(new char[transfer_data_size]);
  Slice data;
  //Log(options_.info_log, "Sending %s from %d", src_fname.c_str(), position);
  if (stop_replication.load(std::memory_order_acquire)) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Backup Stopped");
  }

  size_t buffer_to_read = (copy_file_buffer_size < transfer_data_size) ?
                          copy_file_buffer_size : transfer_data_size;
  s = src_file->Skip(position);
  if (!s.ok()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Could not skip");
  }
  s = src_file->Read(buffer_to_read, &data, buf.get());
  if (!s.ok()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Could read data");
  }
  _return.src_dir = file_info.src_dir;
  _return.src_fname = file_info.src_fname;
  _return.position = position;
  _return.data = data.ToString();
  _return.size = data.size();

  return ;
}

void ReplicationHandler::PeriodicalUpdate(ReplicationFileData& _return,
                                          const int64_t seq) {
  std::unique_ptr<TransactionLogIterator> iter; 
  Status st = db->GetUpdatesSince(seq, &iter);
  if(!st.ok()) {
    throw ReplicationError(ReplicationErrorType::SERVER_ERROR,
                           "Could get iterator");
  }
   
  // if has no update return
  TransactionLogIterator *tlit = iter.get();
  BatchResult bres = tlit->GetBatch();
  WriteBatch *wb   = bres.writeBatchPtr.get();
  _return.data = wb->Data();
  _return.size = _return.data.size();
  _return.position = bres.sequence;
}

// --- ReplicationMaster methods ------

ReplicationMaster::ReplicationMaster(DB* _db, int _port) {
    db = _db;
    port = _port;
}

ReplicationMaster::~ReplicationMaster() {
  StopReplication();
  delete db;
}

Status ReplicationMaster::Open(ReplicationMaster* master, DB* _db, const int _port) {
  if(!_db) return Status::NotFound("DB must be opened");

  master = new ReplicationMaster(_db, _port);
  return master->StartReplication();
}
    
Status ReplicationMaster::StartReplication() {
  using boost::shared_ptr;
  using namespace apache::thrift;
  
  shared_ptr<ReplicationHandler> handler(new ReplicationHandler(db));
  shared_ptr<TProcessor> 
      processor(new ReplicationProcessor(handler));
  shared_ptr<transport::TServerTransport> 
      serverTransport(new transport::TServerSocket(port));    
  shared_ptr<transport::TTransportFactory> 
      transportFactory(new transport::TBufferedTransportFactory());
  shared_ptr<protocol::TProtocolFactory> 
      protocolFactory(new protocol::TBinaryProtocolFactory());
  shared_ptr<concurrency::ThreadManager> 
      threadManager = concurrency::ThreadManager::newSimpleThreadManager(15);
  shared_ptr<concurrency::PosixThreadFactory> threadFactory = 
      shared_ptr<concurrency::PosixThreadFactory>
      (new concurrency::PosixThreadFactory());
  threadManager->threadFactory(threadFactory);
  try {
    threadManager->start();
  } catch (const concurrency::InvalidArgumentException& e) {
    //  } catch (const TException& e) {
    return Status::InvalidArgument("Thrift threadManager error");
  }

  server = new server::TThreadPoolServer(processor, 
                                         serverTransport, transportFactory, 
                                         protocolFactory, threadManager);
  auto replication_thread = std::thread(&ReplicationMaster::PeriodicalSync,
                                               std::ref(*this));
  replication_thread.detach();
  return Status::OK();
}

void ReplicationMaster::PeriodicalSync() {
  server->serve();
}

void ReplicationMaster::StopReplication() {
  server->stop();
}

} // namespace rocksdb

